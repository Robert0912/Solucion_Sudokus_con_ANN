{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sudokus_training10k.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1oZpZ7fYeUNnBIMUlMVaz7ca7yJRh7yvk",
      "authorship_tag": "ABX9TyPDXRmBvM0v7IMToTNXPhq5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Robert0912/Solucion_Sudokus_con_ANN/blob/main/Sudokus_training10k.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l33ZINuDaB_0"
      },
      "source": [
        "### Importación de librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hapvySv-c7EJ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as kr\n",
        "from keras.optimizers import Adam \n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH7TovvBaHKN"
      },
      "source": [
        "### Funciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRSVpFoeZgKg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0a455f32-ff50-430d-b61b-5ab996f91367"
      },
      "source": [
        "def sumafc(vec):\n",
        "  constante=9\n",
        "  sumafil=np.zeros(constante)\n",
        "  sumacol=np.zeros(constante)\n",
        "  sumacuad=np.zeros(constante)\n",
        "  sumas=np.zeros(constante*3)\n",
        "  for i in range (constante):\n",
        "    sumafil[i]=sum(vec[0,i:81:constante])\n",
        "    sumacol[i]=sum(vec[0,constante*i:(constante*i+constante)])\n",
        "  #print(sumafil)\n",
        "  #print(sumacol)\n",
        "  i=0\n",
        "  #sumacuad[0]=sum(vec[0,constante*i:(constante*i+2):1])+sum(vec[0,constante*(i+1):(constante*i+2):1])\n",
        "  sumacuad[0]=sum(vec[0,0:3])+sum(vec[0,9:12])+sum(vec[0,18:21]);sumacuad[1]=sum(vec[0,3:6])+sum(vec[0,12:15])+sum(vec[0,21:24]);sumacuad[2]=sum(vec[0,6:9])+sum(vec[0,15:18])+sum(vec[0,24:27])\n",
        "  sumacuad[3]=sum(vec[0,27:30])+sum(vec[0,36:39])+sum(vec[0,45:48]);sumacuad[4]=sum(vec[0,30:33])+sum(vec[0,39:42])+sum(vec[0,48:51]);sumacuad[5]=sum(vec[0,33:36])+sum(vec[0,42:45])+sum(vec[0,51:54])\n",
        "  sumacuad[6]=sum(vec[0,54:57])+sum(vec[0,63:66])+sum(vec[0,72:75]);sumacuad[7]=sum(vec[0,57:60])+sum(vec[0,66:69])+sum(vec[0,75:78]);sumacuad[8]=sum(vec[0,60:63])+sum(vec[0,69:72])+sum(vec[0,78:81])\n",
        "  #print(sumacuad)\n",
        "  sumas[0:9]=sumafil\n",
        "  sumas[9:18]=sumacol\n",
        "  sumas[18:27]=sumacuad\n",
        "  #print(sumas)\n",
        "  return sumas\n",
        "\n",
        "def SeparadorBinario(V,N):\n",
        "  Z=np.arange(9*N)\n",
        "  V_Bin=np.zeros_like(Z)\n",
        "  k=0\n",
        "  for i in range(N):\n",
        "    for j in range(9):\n",
        "      if V[i]==(j+1):\n",
        "        V_Bin[k]=int(1)\n",
        "      else:\n",
        "        V_Bin[k]=int(0)\n",
        "      k=k+1\n",
        "  k=0\n",
        "  return V_Bin\n",
        "\n",
        "#elecciones=np.zeros((1,729))\n",
        "def SeleccionNumero(Mat,Nel):\n",
        "  i=0\n",
        "  Nsalidas=81\n",
        "  selecciones=np.zeros((1,Nsalidas))\n",
        "  for i in range (Nsalidas):\n",
        "    j=0\n",
        "    if i==0:\n",
        "      selecciones[0,i]=np.argmax(Mat[0,0:9])+1\n",
        "    else:\n",
        "      selecciones[0,i]=np.argmax(Mat[0,9*i:(9*i+9)])+1\n",
        "  return selecciones\n",
        "\n",
        "def EleccionNumero(Mat,Nel):\n",
        "  i=0\n",
        "  elecciones=np.zeros((1,729))\n",
        "  Nsalidas=81\n",
        "  for i in range (Nsalidas):\n",
        "    j=0\n",
        "    if i==0:\n",
        "      elecciones[0,i+np.argmax(Mat[0,9*i:(9*i+9)])]=1\n",
        "    else:\n",
        "      elecciones[0,i*9+np.argmax(Mat[0,9*i:(9*i+9)])]=1\n",
        "  return elecciones\n",
        "\n",
        "def accuracy(predicted_labels, actual_labels):\n",
        "  diff = predicted_labels[0] - actual_labels[0]\n",
        "  return (float(np.count_nonzero(diff==0)) / len(diff))\n",
        "\n",
        "def rendimiento(x,y,y_predict):\n",
        "  diff = y_predict [[0]] - y[[0]]\n",
        "  iguales_y_vs_ypredict=(float(np.count_nonzero(diff==0)))\n",
        "  correctos_previos=np.count_nonzero(x[[0]])\n",
        "  diferencia=iguales_y_vs_ypredict-correctos_previos\n",
        "  if diferencia>0:\n",
        "    return diferencia/((81)-correctos_previos)\n",
        "  else:\n",
        "    return diferencia/(correctos_previos)\n",
        "\n",
        "'''def rendimiento(x,y,y_predict):\n",
        "  diff = y_predict - y\n",
        "  iguales_y_vs_ypredict=(float(np.count_nonzero(diff==0)))\n",
        "  correctos_previos=np.count_nonzero(x)\n",
        "  diferencia=iguales_y_vs_ypredict-correctos_previos\n",
        "  if diferencia>0:\n",
        "    return diferencia/(len(x)-correctos_previos)\n",
        "  else:\n",
        "    return diferencia/(correctos_previos)'''\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def rendimiento(x,y,y_predict):\\n  diff = y_predict - y\\n  iguales_y_vs_ypredict=(float(np.count_nonzero(diff==0)))\\n  correctos_previos=np.count_nonzero(x)\\n  diferencia=iguales_y_vs_ypredict-correctos_previos\\n  if diferencia>0:\\n    return diferencia/(len(x)-correctos_previos)\\n  else:\\n    return diferencia/(correctos_previos)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDMwBoo5aKgw"
      },
      "source": [
        "### Lectura del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u5TX_uPZ_Uu",
        "outputId": "4fc05778-6d9d-49ff-9e01-e1eb523e9365"
      },
      "source": [
        "#Cargar los datos .csv\n",
        "numtest=2500\n",
        "numdatos=10000+numtest\n",
        "path='C:/Users/PC/Desktop/Universidad/Javeriana_10_Semestre/Inteligencia_Artificial/Proyecto/' \n",
        "#df=pd.read_csv(path + 'sudoku.csv', sep=',',header=0)\n",
        "sudokus = next(pd.read_csv('sudoku.csv', chunksize=(numdatos))).values\n",
        "print(sudokus)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['004300209005009001070060043006002087190007400050083000600000105003508690042910300'\n",
            "  '864371259325849761971265843436192587198657432257483916689734125713528694542916378']\n",
            " ['040100050107003960520008000000000017000906800803050620090060543600080700250097100'\n",
            "  '346179258187523964529648371965832417472916835813754629798261543631485792254397186']\n",
            " ['600120384008459072000006005000264030070080006940003000310000050089700000502000190'\n",
            "  '695127384138459672724836915851264739273981546946573821317692458489715263562348197']\n",
            " ...\n",
            " ['003009850010602090004070301080010700007000120090080630542800070068000004030057000'\n",
            "  '673149852815632497924578361386215749457396128291784635542861973768923514139457286']\n",
            " ['005000079104503060600040005008020000350008200006000710400061090900705304027900080'\n",
            "  '835612479174593862692847135718426953359178246246359718483261597961785324527934681']\n",
            " ['004608070090000000526000800040090050608030092000105403000350067900247010013900200'\n",
            "  '134628579897513624526479831341892756658734192279165483482351967965247318713986245']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWdfA4Lrc-BE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2699b9fe-790b-4a5f-fa47-868187111a64"
      },
      "source": [
        "quizzes, solutions = sudokus.T\n",
        "#flatX = np.array([np.reshape([int(d) for d in flatten_grid], (9, 9)) for flatten_grid in quizzes])\n",
        "a =  np.array([np.reshape([int(d) for d in flatten_grid], (1, 81)) for flatten_grid in quizzes])\n",
        "b =  np.array([np.reshape([int(d) for d in flatten_grid], (1, 81)) for flatten_grid in solutions])\n",
        "aux_a=a[0];\n",
        "aux_b=b[0];\n",
        "for i in range(len(a)-1):\n",
        "    aux_a=np.vstack((aux_a,a[i+1]))\n",
        "    aux_b=np.vstack((aux_b,b[i+1]))\n",
        "sudokus_inicio=aux_a\n",
        "sudokus_solucion=aux_b\n",
        "\n",
        "print(sudokus_inicio.shape)\n",
        "print(sudokus_solucion.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12500, 81)\n",
            "(12500, 81)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQNpRWODwmwt"
      },
      "source": [
        "numentradas=729\n",
        "x1=np.zeros((numdatos,numentradas))\n",
        "#y=np.zeros((numdatos,numentradas))\n",
        "y1=np.zeros((numdatos,729))\n",
        "for i in range(int(sudokus_inicio.size/81)):\n",
        "  x1[i,0:729]=SeparadorBinario(np.transpose(sudokus_inicio[[i]]),sudokus_inicio[[i]].size)\n",
        "  #x[i,729:756]=sumafc(sudokus_inicio[[i]])\n",
        "  y1[i,0:729]=SeparadorBinario(np.transpose(sudokus_solucion[[i]]),sudokus_solucion[[i]].size)\n",
        "  #y[i,729:756]=sumafc(sudokus_solucion[[i]])\n",
        "#print(x[[0]]==x[[100]])\n",
        "#print(x[[0]]==SeparadorBinario(np.transpose(sudokus_inicio[[0]]),sudokus_inicio[[0]].size))\n",
        "#print(y[[0]])\n",
        "#print(np.reshape(sudokus_inicio[[0]],(9,9)))\n",
        "\n",
        "x=x1[0:numdatos-numtest,:]\n",
        "y=y1[0:numdatos-numtest,:]\n",
        "\n",
        "xtest=x1[numdatos-numtest:numdatos,:]\n",
        "ytest=y1[numdatos-numtest:numdatos,:]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKlKXmOadAeM",
        "outputId": "7b207a5a-3d86-4bcb-bf9b-edab93e03bc6"
      },
      "source": [
        "#from IPython.core.display import display, HTML\n",
        "# learning rate\n",
        "#nn = [81, 200, 200, 729, 81]  # número de neuronas por capa. note que acá están las de entrada y salida, no solo las ocultas\n",
        "#nn = [81, 200, 200, 81]\n",
        "#nn = [numentradas, 2000, 2000, 1800, 729]\n",
        "nn = [numentradas, 2000, 2000, 729]\n",
        "\n",
        "# Creamos el objeto que contendrá a nuestra red neuronal, como\n",
        "# secuencia de capas.\n",
        "model = kr.Sequential()\n",
        "adam = Adam(lr=.001)\n",
        "# Añadimos la capa 1\n",
        "l1 = model.add(kr.layers.Dense(nn[1], activation='relu'))\n",
        "\n",
        "# Añadimos la capa 2\n",
        "l2 = model.add(kr.layers.Dense(nn[2], activation='relu'))\n",
        "\n",
        "# Añadimos la capa 3\n",
        "l3 = model.add(kr.layers.Dense(nn[3], activation='softmax'))\n",
        "\n",
        "# Añadimos la capa 4\n",
        "#l4 = model.add(kr.layers.Dense(nn[4]))\n",
        "\n",
        "# Compilamos el modelo, definiendo la función de coste y el optimizador.\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam)\n",
        "\n",
        "# Y entrenamos al modelo. Sin callbacks \n",
        "model.fit(x, y, epochs=500,batch_size=10000)\n",
        "#model.fit(X_train, y_train, epochs=1000)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7341\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7335\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7328\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7322\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7315\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7307\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7296\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7283\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7267\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7248\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7226\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7201\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7173\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7142\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7108\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7070\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7030\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6987\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6947\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6917\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6887\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6849\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6827\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6787\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6756\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6716\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6687\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6649\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6618\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6589\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6557\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6532\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6505\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6480\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6457\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6437\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6415\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6397\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6380\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6363\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6348\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6335\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6323\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6315\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6312\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6316\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6310\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6291\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6284\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6279\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6262\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6257\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6241\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6234\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6221\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6213\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6205\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6196\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6188\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6180\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6171\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6164\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6156\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6149\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6141\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6134\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6127\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6121\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6115\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6108\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6103\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6097\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6092\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6089\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6088\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6093\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6096\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6092\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6081\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6082\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6086\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6076\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6077\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6073\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6061\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6057\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6046\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6044\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6035\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6031\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6024\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6018\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6013\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6008\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6001\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5997\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5990\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5986\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5981\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5977\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5972\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5969\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5965\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5961\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5958\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5956\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5956\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5957\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5958\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5963\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5961\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5957\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5950\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5951\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5951\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5948\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5946\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5941\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5934\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5931\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5924\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5921\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5914\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5909\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5904\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5899\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5893\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5891\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5884\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5881\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5878\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5874\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5871\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5870\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5867\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5866\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5865\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5863\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5860\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5856\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5860\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5856\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5856\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5856\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5855\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5855\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5853\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5852\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5849\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5849\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5840\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5839\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5833\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5827\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5823\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5820\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5816\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5812\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5810\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5807\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5802\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5802\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5800\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5799\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5798\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5794\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5797\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5801\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5803\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5799\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5802\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5804\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5805\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5803\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5798\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5791\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5788\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5786\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5781\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5777\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5770\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5767\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5760\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5758\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5754\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5749\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5745\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5744\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5739\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5737\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5734\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5730\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5729\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5726\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5726\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5722\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5723\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5723\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5722\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5720\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5721\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5722\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5718\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5720\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5719\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5716\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5716\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5712\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5711\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5711\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5705\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5705\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5703\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5699\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5698\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5697\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5694\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5694\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5691\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5691\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5688\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5686\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5683\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5685\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5682\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5680\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5682\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5681\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5678\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5678\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5674\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5671\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5672\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5665\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5665\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5661\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5658\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5656\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5652\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5651\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5648\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5644\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5643\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5643\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5640\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5638\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5641\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5641\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5638\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5639\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5640\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5640\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5636\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5635\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5641\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5639\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5636\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5637\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5631\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5630\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5626\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5623\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5617\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5613\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5610\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5608\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5605\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5602\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5596\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5597\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5592\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5590\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5591\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5592\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5590\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5591\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5589\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5592\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5595\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5597\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5599\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5601\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5600\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5603\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5602\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5598\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5588\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5592\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5591\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5586\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5583\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5578\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5576\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5575\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5573\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5567\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5564\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5565\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5559\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5560\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5555\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5554\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5552\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5553\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5553\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5546\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5547\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5545\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5545\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5545\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5543\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5543\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5543\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5542\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5542\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5544\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5543\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5543\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5539\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5549\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5548\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5553\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5555\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5554\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5551\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5543\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5552\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5566\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5573\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5580\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5580\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5579\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5578\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5594\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5600\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5596\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5602\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5603\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5599\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5611\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5612\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5604\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5605\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5592\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5613\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5635\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5634\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5651\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5666\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5692\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5691\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5701\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5715\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5734\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5733\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5764\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5791\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5827\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5846\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5855\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5855\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5871\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5870\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5917\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5905\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5886\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5878\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5868\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5857\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5860\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5869\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5871\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5850\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5843\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5826\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5815\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5793\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5809\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5804\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5800\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5791\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5787\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5768\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5769\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5754\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5732\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5718\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5709\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5706\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5716\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5745\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5726\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5729\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5744\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5748\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5752\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5760\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5758\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5754\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5744\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5739\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5728\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5717\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5706\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5706\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5700\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5695\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5693\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5704\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5705\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5719\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5735\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5744\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5755\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5777\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5810\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5835\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5839\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5856\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5881\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5893\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5914\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5926\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5916\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5901\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5894\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5882\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5892\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5896\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5882\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5892\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5897\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5871\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5869\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5864\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5841\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5828\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5826\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5805\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5798\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5789\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5777\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5822\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5819\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5804\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5816\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5806\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5813\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5817\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5826\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5827\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5829\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5824\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5815\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5805\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5811\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5804\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5814\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5823\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5825\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5835\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5839\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5844\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5845\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5855\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5859\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5869\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5874\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5871\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5914\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5932\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5960\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5993\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5996\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6017\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6041\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6037\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6067\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6075\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6085\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6094\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6102\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6114\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6114\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6102\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6131\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6118\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6128\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6127\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6157\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6173\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6146\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6177\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6175\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6167\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6173\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6244\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6223\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6238\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6245\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8cb6278208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrtLS4IHpbKP"
      },
      "source": [
        "model=kr.models.load_model(\"modelo_training10k.h5\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdwGf2hikOfM",
        "outputId": "388c52ef-6004-435a-da52-9f39dd83ac7a"
      },
      "source": [
        "yyyy=np.zeros((1,numentradas))\n",
        "yyy=np.array([[0,0,4,3,0,0,2,0,9,0,0,5,0,0,9,0,0,1,0,7,0,0,6,0,0,4,3,0,0,6,0,0,2,0,8,7,1,9,0,0,0,7,4,0,0,0,5,0,0,8,3,0,0,0,6,0,0,0,0,0,1,0,5,0,0,3,5,0,8,6,9,0,0,4,2,9,1,0,3,0,0]])\n",
        "#yyy=np.array([[4,5,0,0,0,0,0,0,0,0,0,1,6,0,0,7,9,0,3,0,7,2,0,0,1,0,0,0,0,0,8,5,0,9,0,2,0,0,2,1,6,9,3,0,4,5,0,0,0,0,0,0,8,0,0,6,8,0,9,4,0,0,1,0,7,0,5,0,8,0,6,0,0,0,0,0,1,0,0,2,3]])\n",
        "yy=np.transpose(yyy)\n",
        "print(np.reshape(yyy,(9,9)))\n",
        "\n",
        "#x[[i]]=SeparadorBinario(np.transpose(sudokus_inicio[[i]]),sudokus_inicio[[i]].size)\n",
        "\n",
        "#prediccion=model.predict(yyy)\n",
        "#prediccion_proba=model.predict_proba(yyy)\n",
        "yyyy[0,0:729]=SeparadorBinario(np.transpose(yyy),yyy.size)\n",
        "#yyyy[0,729:756]=sumafc(yyy)\n",
        "print(yyyy.shape)\n",
        "\n",
        "prediccion=model.predict(yyyy)\n",
        "prediccion_proba=model.predict_proba(yyyy)\n",
        "\n",
        "#pred=np.round(prediccion)\n",
        "#print(np.reshape(pred,(9,9))\n",
        "\n",
        "#print(np.reshape(prediccion,(9,9)))\n",
        "#print(np.reshape(prediccion_proba,(27,27)))\n",
        "\n",
        "\n",
        "print(prediccion_proba[0,0:9])\n",
        "#print(prediccion_proba.shape)\n",
        "print(prediccion[0,0:9])\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 4 3 0 0 2 0 9]\n",
            " [0 0 5 0 0 9 0 0 1]\n",
            " [0 7 0 0 6 0 0 4 3]\n",
            " [0 0 6 0 0 2 0 8 7]\n",
            " [1 9 0 0 0 7 4 0 0]\n",
            " [0 5 0 0 8 3 0 0 0]\n",
            " [6 0 0 0 0 0 1 0 5]\n",
            " [0 0 3 5 0 8 6 9 0]\n",
            " [0 4 2 9 1 0 3 0 0]]\n",
            "(1, 729)\n",
            "WARNING:tensorflow:From <ipython-input-15-2c7b2a5537ac>:16: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use `model.predict()` instead.\n",
            "[2.8173405e-05 9.6177180e-05 4.0699229e-05 6.3799758e-04 5.3232670e-04\n",
            " 1.3866695e-04 1.5572006e-04 1.2874287e-03 4.2614370e-04]\n",
            "[2.8173405e-05 9.6177180e-05 4.0699229e-05 6.3799758e-04 5.3232670e-04\n",
            " 1.3866695e-04 1.5572006e-04 1.2874287e-03 4.2614370e-04]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spnr4ghskeD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c791e5e1-815c-4f36-8a62-3a580a6a8264"
      },
      "source": [
        "respuesta=np.reshape(SeleccionNumero(prediccion,prediccion.size),(9,9))\n",
        "print(respuesta)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8. 6. 4. 3. 3. 1. 7. 5. 9.]\n",
            " [3. 2. 5. 8. 4. 9. 7. 6. 1.]\n",
            " [9. 7. 1. 2. 6. 5. 5. 4. 3.]\n",
            " [4. 3. 6. 1. 5. 2. 5. 8. 7.]\n",
            " [1. 8. 8. 6. 5. 7. 5. 3. 2.]\n",
            " [2. 5. 7. 4. 4. 3. 9. 1. 6.]\n",
            " [6. 8. 9. 7. 7. 4. 1. 9. 5.]\n",
            " [7. 1. 3. 5. 2. 8. 6. 9. 4.]\n",
            " [9. 4. 2. 9. 1. 6. 3. 3. 8.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "idsLTfMJGVxz",
        "outputId": "328a3d08-ab23-48dd-9acf-95fcd5228063"
      },
      "source": [
        "'''y_true = [[0., 1.], [0., 0.]]\n",
        "y_pred = [[0.0006, 0.0004], [0.000067, 0.00043]]\n",
        "# Using 'auto'/'sum_over_batch_size' reduction type.\n",
        "bce = tf.keras.losses.BinaryCrossentropy()\n",
        "bce(y_true, y_pred).numpy()'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"y_true = [[0., 1.], [0., 0.]]\\ny_pred = [[0.0006, 0.0004], [0.000067, 0.00043]]\\n# Using 'auto'/'sum_over_batch_size' reduction type.\\nbce = tf.keras.losses.BinaryCrossentropy()\\nbce(y_true, y_pred).numpy()\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUZRqYcKKqKc",
        "outputId": "85bb5825-fb5f-4911-e941-70c4406c9c3c"
      },
      "source": [
        "yyyy1=np.zeros((1,numentradas))\n",
        "yyy1=np.array([[0,4,0,1,0,0,0,5,0,1,0,7,0,0,3,9,6,0,5,2,0,0,0,8,0,0,0,0,0,0,0,0,0,0,1,7,0,0,0,9,0,6,8,0,0,8,0,3,0,5,0,6,2,0,0,9,0,0,6,0,5,4,3,6,0,0,0,8,0,7,0,0,2,5,0,0,9,7,1,0,0]])\n",
        "\n",
        "print(yyy1.shape)\n",
        "\n",
        "yyyy1[0,0:729]=SeparadorBinario(np.transpose(yyy1),yyy1.size)\n",
        "#yyyy1[0,729:756]=sumafc(yyyy1)\n",
        "prediccion1=model.predict(yyyy1)\n",
        "\n",
        "respuesta1=np.reshape(SeleccionNumero(prediccion1,prediccion1.size),(9,9))\n",
        "\n",
        "print(respuesta1)\n",
        "#346179258187523964529648371965832417472916835813754629798261543631485792254397186"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 81)\n",
            "[[3. 4. 6. 1. 4. 9. 3. 5. 8.]\n",
            " [1. 8. 7. 5. 2. 3. 9. 6. 4.]\n",
            " [5. 2. 9. 6. 4. 8. 3. 7. 4.]\n",
            " [9. 6. 6. 8. 3. 2. 4. 1. 7.]\n",
            " [4. 7. 2. 9. 3. 6. 8. 1. 5.]\n",
            " [8. 1. 3. 7. 5. 2. 6. 2. 9.]\n",
            " [7. 9. 8. 2. 6. 1. 5. 4. 8.]\n",
            " [6. 3. 1. 4. 8. 5. 7. 9. 2.]\n",
            " [2. 5. 4. 3. 9. 7. 1. 8. 6.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcN-NJ5bMDZI",
        "outputId": "87ec48fa-14a0-4084-d844-b7cabf8857cc"
      },
      "source": [
        "yyyy2=np.zeros((1,numentradas))\n",
        "yyy2=np.array([[0,7,0,0,0,0,4,0,9,4,1,0,0,5,0,0,0,0,0,0,5,3,0,0,0,2,7,3,0,4,8,0,0,5,0,0,0,2,8,0,3,6,0,9,0,7,0,6,4,0,9,0,1,0,0,0,0,9,0,0,0,0,0,6,0,2,1,8,0,0,3,0,0,0,0,0,4,5,8,7,6]])\n",
        "print(yyy2.shape)\n",
        "\n",
        "yyyy2[0,0:729]=SeparadorBinario(np.transpose(yyy2),yyy2.size)\n",
        "#yyyy2[0,729:756]=sumafc(yyyy2)\n",
        "prediccion2=model.predict(yyyy2)\n",
        "\n",
        "respuesta2=np.reshape(SeleccionNumero(prediccion2,prediccion2.size),(9,9))\n",
        "\n",
        "print(respuesta2)\n",
        "\n",
        "#070000409 - 273618459\n",
        "#410050000 - 419752683\n",
        "#005300027 - 865394127\n",
        "#304800500 - 394871562\n",
        "#028036090 - 128536794\n",
        "#706409010 - 756429318\n",
        "#000900000 - 587963241\n",
        "#602180030 - 642187935\n",
        "#000045876 - 931245876\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 81)\n",
            "[[2. 7. 3. 6. 5. 1. 4. 8. 9.]\n",
            " [4. 1. 3. 2. 5. 8. 6. 6. 3.]\n",
            " [9. 8. 8. 3. 9. 4. 4. 2. 7.]\n",
            " [3. 9. 4. 8. 7. 7. 5. 4. 2.]\n",
            " [5. 2. 8. 5. 3. 6. 7. 9. 4.]\n",
            " [7. 2. 6. 4. 2. 4. 3. 1. 3.]\n",
            " [1. 4. 3. 9. 6. 3. 2. 4. 1.]\n",
            " [6. 9. 2. 1. 8. 5. 9. 3. 5.]\n",
            " [1. 9. 3. 2. 4. 5. 8. 7. 6.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG9pQM72X8a3",
        "outputId": "d6d28aef-20af-46d6-ec9d-82f877070cd3"
      },
      "source": [
        "print(xtest.shape)\n",
        "#predictions=np.zeros((1,numdatos))\n",
        "acc=np.zeros(numtest)\n",
        "ren=np.zeros(numtest)\n",
        "#prediction=SeleccionNumero(model.predict(xtest[[0]]),model.predict(xtest[[0]]).size)\n",
        "for i in range (numtest):\n",
        "  #elecciones=np.zeros((1,729))\n",
        "  prediction=SeleccionNumero(model.predict(xtest[[i]]),model.predict(xtest[[i]]).size)\n",
        "  acc[i]=accuracy(prediction,sudokus_solucion[[numdatos-numtest+i]])\n",
        "  ren[i]=rendimiento(sudokus_inicio[[numdatos-numtest+i]],sudokus_solucion[[numdatos-numtest+i]],prediction)\n",
        "  #print(acc)\n",
        "\n",
        "#print(np.reshape(sudokus_inicio[[1000]],(9,9)))\n",
        "#print(np.reshape(prediction,(9,9)))\n",
        "print(elecciones.shape)\n",
        "print(ytest[[-1]].shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2500, 729)\n",
            "Accuracy:  [0.67901235 0.61728395 0.67901235 ... 0.56790123 0.75308642 0.65432099]\n",
            "Rendimiento:  [0.67901235 0.61728395 0.67901235 ... 0.56790123 0.75308642 0.65432099]\n",
            "(1, 729)\n",
            "(1, 729)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXHsqW5bmxzX",
        "outputId": "997a14f9-bd69-4e1f-aa19-b2053e7781dd"
      },
      "source": [
        "print(\"Accuracy: \",acc)\n",
        "np.mean(accmax\n",
        "accmax=max(acc)\n",
        "accmin=min(acc)\n",
        "accmean=sum(acc)/numtest\n",
        "print(\"La exactitud máxima es: \",accmax,\"\\nLa exactitud mínima es: \",accmin,\"\\nLa exactitud del conjunto de validación es: \", accmean)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  [0.67901235 0.61728395 0.67901235 ... 0.56790123 0.75308642 0.65432099]\n",
            "La exactitud máxima es:  0.8148148148148148 \n",
            "La exactitud mínima es:  0.48148148148148145 \n",
            "La exactitud del conjunto de validación es:  0.6538765432098755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-st6IMGoM7W",
        "outputId": "51e87dc5-58bd-4361-eae7-45e2af4c18fd"
      },
      "source": [
        "print(\"Rendimiento: \",ren)\n",
        "renmax=max(ren)\n",
        "renmin=min(ren)\n",
        "renmean=sum(ren)/numtest\n",
        "print(\"El rendimiento máximo es: \",renmax,\"\\nEl rendimiento mínimo es: \",renmin,\"\\nEl rendimiento del conjunto de validación es: \", renmean)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rendimiento:  [0.44680851 0.34042553 0.44680851 ... 0.27083333 0.58333333 0.40425532]\n",
            "El rendimiento máximo es:  0.6875 \n",
            "El rendimiento mínimo es:  0.14285714285714285 \n",
            "El rendimiento del conjunto de validación es:  0.40609733065139125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEXTMPTdWw0m",
        "outputId": "b97d24ef-2a82-483a-980d-701611979daa"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 2000)              1460000   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2000)              4002000   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 729)               1458729   \n",
            "=================================================================\n",
            "Total params: 6,920,729\n",
            "Trainable params: 6,920,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68N1tZB0XI-_"
      },
      "source": [
        "# Guardar el Modelo\n",
        "model.save('modelo_training10k.h5')\n",
        "\n",
        "# Recrea exactamente el mismo modelo solo desde el archivo\n",
        "#new_model = keras.models.load_model('path_to_my_model.h5')\n"
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}